{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26a39251-cf46-4917-b8b4-89ae0ad5a060",
   "metadata": {},
   "source": [
    "# Get Voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc02797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyneuphonic import Neuphonic, TTSConfig, Agent\n",
    "from pyneuphonic.player import AudioPlayer\n",
    "\n",
    "api_key = \"172c4d78863aec707d4496f0d5258bff3389e92b2614c8175e7f18575eebc4a5.f13b6de5-100a-4252-b2fd-7a4aa39c852f\" # GET THIS FROM beta.neuphonic.com!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a37179c-23a7-4741-871f-0665cc4c51d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='e564ba7e-aa8d-46a2-96a8-8dffedade48f' name='Annie' tags=['Female', 'Twenties', 'American', 'Relaxing'] model_availability=['neu_hq']\n",
      "id='8e9c4bc8-3979-48ab-8626-df53befc2090' name='Holly' tags=['Female', 'American', 'Midwestern'] model_availability=['neu_fast', 'neu_hq']\n",
      "id='6ffede2d-d96e-4a9b-9d4d-e654b8ef4cf2' name='James' tags=['Male', 'Thirties', 'American'] model_availability=['neu_hq']\n",
      "id='06fde793-8929-45f6-8a87-643196d376e4' name='Jo' tags=['Female', 'Thirties', 'American'] model_availability=['neu_hq']\n",
      "id='ebf2c88e-e69d-4eeb-9b9b-9f3a648787a5' name='Marcus' tags=['Male', 'American'] model_availability=['neu_fast']\n",
      "id='b19687fd-c5c9-4bda-9d52-756c3b10c88e' name='Miles' tags=['Male', 'American', 'Fourties', 'Narrator'] model_availability=['neu_hq']\n",
      "id='f2185de7-e09b-46d7-9b20-8c82ef90524f' name='Wyatt' tags=['Male', 'American'] model_availability=['neu_hq']\n"
     ]
    }
   ],
   "source": [
    "client = Neuphonic(api_key=api_key)\n",
    "voices = client.voices.get()  # get's all available voices\n",
    "\n",
    "for voice in voices:\n",
    "    print(voice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7873904-d588-418f-a742-8d4f7b9c26a7",
   "metadata": {},
   "source": [
    "# Text To Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b7d226-bd6a-4050-97a8-929068eb4c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Neuphonic(api_key=api_key)\n",
    "sse = client.tts.SSEClient()\n",
    "tts_config = TTSConfig(speed=1.05,  voice='8e9c4bc8-3979-48ab-8626-df53befc2090', model=\"neu_hq\")\n",
    "\n",
    "with AudioPlayer() as player:\n",
    "    response = sse.send(\"\"\"Neuphonic generates high quality and low latency text to speech. Experience the speed and clarity of our dynamically powered voice synthesis by entering your text!\"\"\", tts_config=tts_config)\n",
    "    player.play(response)\n",
    "    # player.save_audio('output.wav') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c50a627e-ade2-4809-938b-cc022fef31f1",
   "metadata": {},
   "source": [
    "# Altering Speech Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a3d8e-28a7-4f77-81be-a09591e0d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Neuphonic(api_key=api_key)\n",
    "sse = client.tts.SSEClient()\n",
    "\n",
    "# Below we alter the speed of the model and the voice\n",
    "tts_config = TTSConfig(\n",
    "    speed=1.3,  \n",
    "    voice='b19687fd-c5c9-4bda-9d52-756c3b10c88e', \n",
    "    model=\"neu_hq\"\n",
    ")\n",
    "\n",
    "with AudioPlayer() as player:\n",
    "    response = sse.send(\"\"\"Neuphonic generates high quality and low latency text to speech. Experience the speed and clarity of our dynamically powered voice synthesis by entering your text!\"\"\", tts_config=tts_config)\n",
    "    player.play(response)\n",
    "    # player.save_audio('output.wav') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c417d51-5c88-4ed0-8905-dc416a5171db",
   "metadata": {},
   "source": [
    "# Speech to Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb16bc",
   "metadata": {},
   "source": [
    "Run the example below to create an agent that will greet you and initiate a voice conversation. \n",
    "Speak back to it to initiate a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172908f2-d200-455d-96fc-9cd5d84677c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Does Jaffa cakes fit my diet?\n",
      "Agent: It depends on your specific diet requirements and restrictions.\n",
      "User: Can you\n",
      "Agent: provide me with more details about your diet, such as your dietary restrictions, calorie goals, or specific diet plan?\n",
      "User: me the nutritional information for Jaffa cakes?\n",
      "Agent: Here is the approximate nutritional information for a standard Jaffa cake:\n",
      "- Calories: 45\n",
      "- Fat: 1g\n",
      "- Carbohydrates: 8g\n",
      "- Protein: 1g\n",
      "\n",
      "Please note that nutritional values may vary slightly depending on the brand or recipe.\n",
      "User: Is that correct? I don't know.\n",
      "Agent: The provided nutritional information is an approximation and may vary.\n",
      "User: Check it.\n",
      "Agent: I apologize, but I'm not currently able to browse the internet and check the nutritional information for you. It's best to refer to the specific packaging or consult a reliable source for accurate information.\n",
      "User: Yeah. You don't vaccinate it.\n",
      "Agent: I'm sorry if I was unable to provide the specific information you were looking for. Is there anything else I can assist you with?\n",
      "User: Okay.\n",
      "Agent: If you have any other questions or need further assistance, feel free to ask. I'm here to help!\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      3\u001b[0m agent_id \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39magents\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      4\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAgent 1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou are a helpful agent. Answer in 10 words or less.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     greeting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHi, how can I help you today?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m )[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m agent \u001b[38;5;241m=\u001b[39m Agent(client, agent_id\u001b[38;5;241m=\u001b[39magent_id, tts_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneu_hq\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m agent\u001b[38;5;241m.\u001b[39mstart()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyneuphonic/agents.py:58\u001b[0m, in \u001b[0;36mAgent.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mws\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/asyncio/tasks.py:665\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(delay, result)\u001b[0m\n\u001b[1;32m    661\u001b[0m h \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mcall_later(delay,\n\u001b[1;32m    662\u001b[0m                     futures\u001b[38;5;241m.\u001b[39m_set_result_unless_cancelled,\n\u001b[1;32m    663\u001b[0m                     future, result)\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    667\u001b[0m     h\u001b[38;5;241m.\u001b[39mcancel()\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Candidates 41.\n",
      "Agent: I'm sorry, but I'm not sure what you mean by \"Candidates 41.\" Can you please provide more context or clarify your question?\n",
      "User: 45?\n",
      "Agent: I apologize if there was a misunderstanding, but I'm unsure what \"45\" refers to in this context. Could you please provide more information or specify your question?\n"
     ]
    }
   ],
   "source": [
    "client = Neuphonic(api_key=api_key)\n",
    "\n",
    "agent_id = client.agents.create(\n",
    "    name='Agent 1',\n",
    "    prompt='You are a helpful agent. Answer in 10 words or less.',\n",
    "    greeting='Hi, how can I help you today?'\n",
    ")['data']['id']\n",
    "\n",
    "agent = Agent(client, agent_id=agent_id, tts_model='neu_hq')\n",
    "\n",
    "await agent.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd1026",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m audio_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Path to recorded audio\u001b[39;00m\n\u001b[1;32m     15\u001b[0m api_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.neuphonic.ai/speech-to-text\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with actual endpoint\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m transcription_response \u001b[38;5;241m=\u001b[39m speech_to_text_neuphonic(audio_file, api_url, api_key)\n\u001b[1;32m     18\u001b[0m transcription \u001b[38;5;241m=\u001b[39m transcription_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscription\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscription:\u001b[39m\u001b[38;5;124m\"\u001b[39m, transcription)\n",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m, in \u001b[0;36mspeech_to_text_neuphonic\u001b[0;34m(audio_file_path, api_url, api_key)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspeech_to_text_neuphonic\u001b[39m(audio_file_path, api_url, api_key):\n\u001b[1;32m      4\u001b[0m     headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/octet-stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     }\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(audio_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m audio_file:\n\u001b[1;32m      9\u001b[0m         response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(api_url, headers\u001b[38;5;241m=\u001b[39mheaders, data\u001b[38;5;241m=\u001b[39maudio_file)\n\u001b[1;32m     10\u001b[0m         response\u001b[38;5;241m.\u001b[39mraise_for_status()  \u001b[38;5;66;03m# Ensure the request succeeded\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input.wav'"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def record_until_silence(filename=\"recorded_audio.wav\", sample_rate=44100, silence_threshold=0.01, silence_duration=1.0):\n",
    "    print(\"Listening... (Speak to start recording)\")\n",
    "    \n",
    "    duration_buffer = int(silence_duration * sample_rate)  # Buffer for silence detection\n",
    "    audio_buffer = []\n",
    "    silent_frames = 0\n",
    "\n",
    "    def callback(indata, frames, time, status):\n",
    "        nonlocal silent_frames, audio_buffer\n",
    "        if status:\n",
    "            print(status)\n",
    "\n",
    "        # Check if audio is below silence threshold\n",
    "        if np.max(np.abs(indata)) < silence_threshold:\n",
    "            silent_frames += frames\n",
    "        else:\n",
    "            silent_frames = 0\n",
    "\n",
    "        # Append audio to buffer\n",
    "        audio_buffer.append(indata.copy())\n",
    "\n",
    "        # Stop if silence exceeds threshold duration\n",
    "        if silent_frames >= duration_buffer:\n",
    "            raise sd.CallbackStop\n",
    "\n",
    "    # Record audio in blocks\n",
    "    try:\n",
    "        with sd.InputStream(samplerate=sample_rate, channels=1, callback=callback):\n",
    "            sd.sleep(60000)  # Arbitrary long timeout\n",
    "    except sd.CallbackStop:\n",
    "        print(\"Recording stopped.\")\n",
    "\n",
    "    # Combine and save recorded audio\n",
    "    audio_data = np.concatenate(audio_buffer, axis=0)\n",
    "    write(filename, sample_rate, (audio_data * 32767).astype(np.int16))  # Save as WAV\n",
    "    print(f\"Saved audio to {filename}\")\n",
    "    return filename\n",
    "\n",
    "def main(api_url, api_key):\n",
    "    # Step 1: Record audio until silence\n",
    "    audio_file = record_until_silence()\n",
    "\n",
    "    # Step 2: Send recorded audio to Neuphonic AI for transcription\n",
    "    transcription_response = speech_to_text_neuphonic(audio_file, api_url, api_key)\n",
    "    transcription = transcription_response.get(\"transcription\", \"\")\n",
    "    print(\"Transcription:\", transcription)\n",
    "\n",
    "    # Optional: Use transcription for web scraping or other analysis\n",
    "    if transcription:\n",
    "        results = scrape_web_for_query(transcription)\n",
    "        print(\"Web Scraping Results:\")\n",
    "        for result in results:\n",
    "            print(result)\n",
    "    else:\n",
    "        print(\"No transcription available.\")\n",
    "\n",
    "# Replace with your Neuphonic API details\n",
    "api_url = \"https://api.neuphonic.ai/speech-to-text\"\n",
    "api_key = \"YOUR_API_KEY\"\n",
    "\n",
    "main(api_url, api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d11bf2a",
   "metadata": {},
   "source": [
    "Note: To stop the above cell, you will need to either restart the Jupyter server or terminate the Jupyter server process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
